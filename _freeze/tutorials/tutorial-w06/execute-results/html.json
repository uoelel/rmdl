{
  "hash": "dc058575269ab7013f52197df182397f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"QML -- Week 6\"\nsubtitle: \"Varying effects II\"\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n\n## Introduction\n\n::: callout-warning\nWhen working through these tutorials, **make sure you are in the course Quarto Project** you created.\n\nYou know you are in a Quarto Project because you can see the name of the Project in the top-right corner of RStudio, next to the light-blue cube icon.\n\nIf you see `Project (none)` in the top-right corner, that means **you are not** in a Quarto Project.\n\nTo make sure you are in the Quarto project, you can open the project by going to the project folder in File Explorer (Win) or Finder (macOS) and double click on the `.Rproj` file.\n:::\n\nIn this tutorial you will run a Bayesian model with the data from Martin 2020 (DOI [10.1177/0956797620931108](https://doi.org/10.1177/0956797620931108)). You can get the data by downloading the [zip file](data.zip) with all the data from this course. The Martin 2020 data is in `martin2020/data_anonymized`. The file `martin2020/data_anonymized/README.txt` contains information on the columns found in the data. You will have to bind the English and Kîîtharaka data.\n\nFilter the data to have only \"post-pre\" trials (`trial_type`) and address the following research question:\n\n> Do both English and Kîîtharaka show a preference for post-changed items (i.e. greater accuracy) in both conditions (words and shapes)?\n\nDoes the model converge (or did you get a warning about divergent transitions, convergence, ESS being too low)? If it did not converge, the warning includes the following suggestions, related to the MCMC algorithm:\n\n- Increase the number of iterations (2000 by default): for example, `iter = 4000`.\n- Increase `adapt_delta` (number between 0 and 1, 0.8 by default): for example, `control = list(adapt_delta = 0.9999)`.\n- Increase `max_treedepth` (10 by default): for example, `control = list(max_treedepth = 15)`.\n- Specify more informative priors. You might have not covered priors in QML, but if you did, you can specify weakly informative priors (the default prior are uninformative).\n\n",
    "supporting": [
      "tutorial-w06_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}